{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8fb90-48b6-417d-ab23-545743493c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.7.0  \n",
    "pip install keras==2.7.0 \n",
    "pip install scikit-image==0.22.0 \n",
    "pip install scikit-learn==1.3.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70143d53-983a-4b10-9ab7-aa4e8d7a3cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from datetime import datetime \n",
    "import cv2\n",
    "from PIL import Image\n",
    "from keras import backend, optimizers\n",
    "import glob\n",
    "from tensorflow.keras.models import save_model\n",
    "import pickle\n",
    "from models import Attention_UNet, dice_coef, dice_coef_loss, jacard_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272ae63-a116-41a3-a040-2842fcd4da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed = seed\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b01c50-1c0d-4b10-9f3b-8b72f8737b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = sorted(glob.glob(\"C:/Users/drsaq/OneDrive/Desktop/256_paches/train/images/*.jpg\"))\n",
    "mask_paths = sorted(glob.glob(\"C:/Users/drsaq/OneDrive/Desktop/256_paches/train/masks/*.jpg\"))\n",
    "\n",
    "# Initialize lists to store the images and masks\n",
    "large_images = []\n",
    "large_masks = []\n",
    "\n",
    "# Iterate through the sorted file paths and load images and masks\n",
    "for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "    # Read and process the image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    large_images.append(img)\n",
    "\n",
    "    # Read and process the mask\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.where(mask < 100, 0, 255)\n",
    "\n",
    "    # Convert the mask to boolean data type\n",
    "    mask = mask.astype(bool)\n",
    "    large_masks.append(mask)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "X_train = np.array(large_images)/255.\n",
    "y_train = np.expand_dims((np.array(large_masks)),3) /255.\n",
    "\n",
    "image_paths = sorted(glob.glob(\"C:/Users/drsaq/OneDrive/Desktop/256_paches/val/images/*.jpg\"))\n",
    "mask_paths = sorted(glob.glob(\"C:/Users/drsaq/OneDrive/Desktop/256_paches/val/masks/*.jpg\"))\n",
    "\n",
    "# Initialize lists to store the images and masks\n",
    "large_images = []\n",
    "large_masks = []\n",
    "\n",
    "# Iterate through the sorted file paths and load images and masks\n",
    "for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "    # Read and process the image\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    large_images.append(img)\n",
    "\n",
    "    # Read and process the mask\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    mask = np.where(mask < 100, 0, 255)\n",
    "\n",
    "    # Convert the mask to boolean data type\n",
    "    mask = mask.astype(bool)\n",
    "    large_masks.append(mask)\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "X_test = np.array(large_images)/255.\n",
    "y_test= np.expand_dims((np.array(large_masks)),3) /255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0281b92a-039d-4bb5-aa25-9053d1a19b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = X_train.shape[1]\n",
    "IMG_WIDTH  = X_train.shape[2]\n",
    "IMG_CHANNELS = X_train.shape[3]\n",
    "num_labels = 1  #Binary\n",
    "input_shape = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e74a11-35ad-4943-aca8-240cda99ed2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attention UNet\n",
    "'''\n",
    "att_unet_model = Attention_UNet(input_shape)\n",
    "\n",
    "att_unet_model.compile(optimizer=Adam(lr = 1e-2), loss='binary_crossentropy', \n",
    "              metrics=['accuracy', jacard_coef])\n",
    "\n",
    "save_model(att_unet_model, 'C:/Users/drsaq/OneDrive/Desktop/256_paches/Result/spore_Attention_UNet_model_architecture.h5')\n",
    "print(att_unet_model.summary())\n",
    "start2 = datetime.now() \n",
    "att_unet_history = att_unet_model.fit(X_train, y_train, \n",
    "                    verbose=1,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data=(X_test, y_test ), \n",
    "                    shuffle=False,\n",
    "                    epochs=50)\n",
    "\n",
    "with open('C:/Users/drsaq/OneDrive/Desktop/256_paches/Result/spore_Attention_UNet_model_history.pkl', 'wb') as file:\n",
    "    pickle.dump(att_unet_history.history, file)\n",
    "stop2 = datetime.now()\n",
    "#Execution time of the model \n",
    "execution_time_Att_Unet = stop2-start2\n",
    "print(\"Attention UNet execution time is: \", execution_time_Att_Unet)\n",
    "\n",
    "att_unet_model.save('C:/Users/drsaq/OneDrive/Desktop/256_paches/Result/spore_Attention_UNet_50epochs_CrossEntropy.hdf5')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
